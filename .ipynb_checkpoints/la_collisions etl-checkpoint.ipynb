{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandasql as ps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"X\", \"Y\", \"collision_date\", \"collision_time\", \"day_of_week\", \"intersection\", \"weather_1\", \"location_type\", \"collision_severity\", \"number_killed\", \"number_injured\", \"party_count\", \"primary_coll_factor\", \"pcf_viol_category\", \"hit_and_run\", \"type_of_collision\", \"road_surface\", \"road_cond_1\", \"lighting\", \"control_device\", \"pedestrian_accident\", \"bicycle_accident\", \"motorcycle_accident\", \"truck_accident\", \"alcohol_involved\", \"count_ped_killed\", \"count_ped_injured\", \"count_bicyclist_killed\", \"count_bicyclist_injured\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location_type']=df['location_type'].fillna('N')\n",
    "\n",
    "df['pedestrian_accident']=df['pedestrian_accident'].fillna('N')\n",
    "\n",
    "df['bicycle_accident']=df['bicycle_accident'].fillna('N')\n",
    "\n",
    "df['motorcycle_accident']=df['motorcycle_accident'].fillna('N')\n",
    "\n",
    "df['truck_accident']=df['truck_accident'].fillna('N')\n",
    "df['alcohol_involved']=df['alcohol_involved'].fillna('N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = df.shape[0]\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "\"\"\"rows before: {}, rows after: {}, duplicate rows: {}\"\"\". \\\n",
    "format(rows_before, df.shape[0], rows_before - df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Rows without Geo Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.sqldf(\"select ROUND(X, 0), ROUND(Y, 0), count(*) from df group by 1,2 order by 1 desc,2 desc\", locals())\n",
    "\n",
    "ps.sqldf(\"select * from df where ROUND(X, 0) = 0 or ROUND(Y, 0) = 0\", locals())\n",
    "\n",
    "rows_before = df.shape[0]\n",
    "df = ps.sqldf(\"select * from df where ROUND(X, 0) != 0 and ROUND(Y, 0) != 0\", locals())\n",
    "\n",
    "\"\"\"rows before: {}, rows after: {}, rows dropped: {}\"\"\". \\\n",
    "format(rows_before, df.shape[0], rows_before - df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = ps.sqldf(\"\"\"\n",
    "SELECT\n",
    "1 AS sector,\n",
    "-118.66 AS left,\n",
    "-118.50 AS right,\n",
    "34.32 AS up,\n",
    "34.14 AS down\n",
    "UNION ALL\n",
    "SELECT\n",
    "2 AS sector,\n",
    "-118.50 AS left,\n",
    "-118.34 AS right,\n",
    "34.32 AS up,\n",
    "34.14 AS down         \n",
    "UNION ALL\n",
    "SELECT\n",
    "3 AS sector,\n",
    "-118.36 AS left,\n",
    "-118.14 AS right,\n",
    "34.14 AS up,\n",
    "34.05 AS down\n",
    "UNION ALL\n",
    "SELECT\n",
    "4 AS sector,\n",
    "-118.50 AS left,\n",
    "-118.36 AS right,\n",
    "34.14 AS up,\n",
    "33.91 AS down \n",
    "UNION ALL\n",
    "SELECT\n",
    "5 AS sector,\n",
    "-118.36 AS left,\n",
    "-118.28 AS right,\n",
    "34.05 AS up,\n",
    "33.915 AS down\n",
    "UNION ALL\n",
    "SELECT\n",
    "6 AS sector,\n",
    "-118.28 AS left,\n",
    "-118.13 AS right,\n",
    "34.05 AS up,\n",
    "33.915 AS down\n",
    "UNION ALL\n",
    "SELECT\n",
    "7 AS sector,\n",
    "-118.325 AS left,\n",
    "-118.238 AS right,\n",
    "33.915 AS up,\n",
    "33.7 AS down\n",
    "\n",
    "         \"\"\", locals())\n",
    "\n",
    "\n",
    "location_lookup_df = ps.sqldf(\"\"\"\n",
    "\n",
    "SELECT\n",
    "z2.*,\n",
    "new_left + (new_right - new_left)/2 AS center_x,\n",
    "new_down + (new_up - new_down)/2 AS center_y\n",
    "FROM\n",
    "    (SELECT\n",
    "      sector,\n",
    "      (delta_x*row1) + left AS new_left,\n",
    "      (delta_x*(row1+1)) + left AS new_right,\n",
    "      (delta_y*row2) + down AS new_down,\n",
    "      (delta_y*(row2+1)) + down AS new_up,\n",
    "      x.*,\n",
    "      y.*,\n",
    "      z.*\n",
    "\n",
    "    FROM\n",
    "        (SELECT\n",
    "          sector,\n",
    "          (right - left) / 10 delta_x,\n",
    "          (up - down) / 10 delta_y,\n",
    "          left,\n",
    "          down,\n",
    "          right,\n",
    "          up\n",
    "        FROM df_1\n",
    "        ) x\n",
    "    CROSS JOIN\n",
    "        (\n",
    "        SELECT 0 as row1 UNION ALL\n",
    "        SELECT 1 as row1 UNION ALL\n",
    "        SELECT 2 as row1 UNION ALL\n",
    "        SELECT 3 as row1 UNION ALL\n",
    "        SELECT 4 as row1 UNION ALL\n",
    "        SELECT 5 as row1 UNION ALL\n",
    "        SELECT 6 as row1 UNION ALL\n",
    "        SELECT 7 as row1 UNION ALL\n",
    "        SELECT 8 as row1 UNION ALL\n",
    "        SELECT 9 as row1\n",
    "        ) y \n",
    "        CROSS JOIN\n",
    "        (\n",
    "        SELECT 0 as row2 UNION ALL\n",
    "        SELECT 1 as row2 UNION ALL\n",
    "        SELECT 2 as row2 UNION ALL\n",
    "        SELECT 3 as row2 UNION ALL\n",
    "        SELECT 4 as row2 UNION ALL\n",
    "        SELECT 5 as row2 UNION ALL\n",
    "        SELECT 6 as row2 UNION ALL\n",
    "        SELECT 7 as row2 UNION ALL\n",
    "        SELECT 8 as row2 UNION ALL\n",
    "        SELECT 9 as row2\n",
    "        ) z\n",
    "    ) z2\n",
    "\"\"\", locals())\n",
    "location_lookup_df['index1'] = location_lookup_df.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA = pd.read_csv(\"data/2010_Census_Populations_by_Zip_Code.csv\")\n",
    "dfB = pd.read_csv(\"data/Intersections.csv\")\n",
    "dfC = pd.read_csv(\"data/Regulatory_Signs.csv\")\n",
    "dfD = pd.read_csv(\"data/Street_Lights.csv\")\n",
    "dfE = pd.read_csv(\"data/Stop_and_Yield_Signs.csv\")\n",
    "# dfF = pd.read_csv(\"data/Walkability_Index_Score_2012.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ps.sqldf(\"\"\"\n",
    "select \n",
    "a.*, b.index1, sector\n",
    "from df a\n",
    "INNER JOIN\n",
    "location_lookup_df b\n",
    " ON a.X >= new_left AND a.X < new_right\n",
    "AND a.Y >= new_down AND a.Y < new_up\n",
    "\"\"\", locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uszipcode import ZipcodeSearchEngine\n",
    "search = ZipcodeSearchEngine()\n",
    "# zipcode = search.by_zipcode(90001)\n",
    "res = search.by_city(city=\"Los Angeles\", returns=0)\n",
    "search.export_to_csv(res, \"result.csv\")\n",
    "dfAnew = pd.read_csv(\"data/result.csv\")\n",
    "dfA.columns = dfA.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "dfAcombined = ps.sqldf(\"\"\"\n",
    "SELECT Population, Density, Wealthy, HouseOfUnits, Latitude, Longitude, median_age\n",
    "    from dfAnew a\n",
    "    LEFT JOIN\n",
    "    dfA b ON\n",
    "    a.Zipcode = b.zip_code\n",
    "\"\"\", locals())\n",
    "population_intermediate_df = ps.sqldf(\"\"\"\n",
    "select \n",
    "a.*,\n",
    "b.*,\n",
    "(((center_x - Longitude)*(center_x - Longitude)) + ((center_y - Latitude)*(center_y - Latitude))) AS distance\n",
    "from location_lookup_df a\n",
    "CROSS JOIN\n",
    "dfAcombined b\n",
    "\"\"\", locals())\n",
    "population_final_df = ps.sqldf(\"\"\"\n",
    "select \n",
    "a.index1, Population, Density, Wealthy, HouseOfUnits, median_age\n",
    "from population_intermediate_df a\n",
    "INNER JOIN\n",
    "(select index1, min(distance) AS min_distance from population_intermediate_df group by 1) b\n",
    "ON a.index1 = b.index1 and\n",
    "   a.distance = b.min_distance\n",
    "group by 1\n",
    "order by 1\n",
    "\"\"\", locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_df = ps.sqldf(\"\"\"\n",
    "select\n",
    "index1, count(*) AS intersections\n",
    "FROM\n",
    "    (select index1, LAT, LON\n",
    "    from dfB a\n",
    "    INNER JOIN\n",
    "    location_lookup_df b\n",
    "     ON a.LON >= new_left AND a.LON < new_right\n",
    "    AND a.LAT >= new_down AND a.LAT < new_up\n",
    "    ) x\n",
    "group by 1 \n",
    "order by 1\n",
    "\"\"\", locals())\n",
    "\n",
    "street_lights_df = ps.sqldf(\"\"\"\n",
    "SELECT\n",
    "  index1,\n",
    "  SUM(total_watts) AS total_watts,\n",
    "  SUM(total_lightbulbs) AS total_lightbulbs\n",
    "  \n",
    "FROM\n",
    "(select index1, \n",
    "CASE WHEN TRIM(IFNULL(LAMPA,'')) = '' THEN 0 ELSE SUBSTR(LAMPA, 1, instr(LAMPA,\"W\")) END +\n",
    "CASE WHEN TRIM(IFNULL(LAMPB,'')) = '' THEN 0 ELSE SUBSTR(LAMPB, 1, instr(LAMPB,\"W\")) END +\n",
    "CASE WHEN TRIM(IFNULL(LAMPC,'')) = '' THEN 0 ELSE SUBSTR(LAMPC, 1, instr(LAMPC,\"W\")) END +\n",
    "CASE WHEN TRIM(IFNULL(LAMPD,'')) = '' THEN 0 ELSE SUBSTR(LAMPD, 1, instr(LAMPD,\"W\")) END +\n",
    "CASE WHEN TRIM(IFNULL(LAMPE,'')) = '' THEN 0 ELSE SUBSTR(LAMPE, 1, instr(LAMPE,\"W\")) END +\n",
    "CASE WHEN TRIM(IFNULL(LAMPF,'')) = '' THEN 0 ELSE SUBSTR(LAMPF, 1, instr(LAMPF,\"W\")) END AS total_watts,\n",
    "CASE WHEN TRIM(IFNULL(LAMPA,'')) = '' THEN 0 ELSE 1 END +\n",
    "CASE WHEN TRIM(IFNULL(LAMPB,'')) = '' THEN 0 ELSE 1 END +\n",
    "CASE WHEN TRIM(IFNULL(LAMPC,'')) = '' THEN 0 ELSE 1 END +\n",
    "CASE WHEN TRIM(IFNULL(LAMPD,'')) = '' THEN 0 ELSE 1 END +\n",
    "CASE WHEN TRIM(IFNULL(LAMPE,'')) = '' THEN 0 ELSE 1 END +\n",
    "CASE WHEN TRIM(IFNULL(LAMPF,'')) = '' THEN 0 ELSE 1 END AS total_lightbulbs\n",
    "from dfD a\n",
    "INNER JOIN\n",
    "location_lookup_df b\n",
    " ON a.X >= new_left AND a.X < new_right\n",
    "AND a.Y >= new_down AND a.Y < new_up\n",
    ") x\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\", locals())\n",
    "\n",
    "regulatory_signs_df = ps.sqldf(\"\"\"\n",
    "SELECT\n",
    "  index1,\n",
    "  SUM(one_way_sign) AS one_way_signs,\n",
    "  SUM(speed_limit_sign) AS speed_limit_signs,\n",
    "  SUM(no_u_turn_sign) AS no_u_turn_signs\n",
    "FROM\n",
    "(select index1,\n",
    "CASE WHEN lower(tooltip) like '%one way%' THEN 1 ELSE 0 END AS one_way_sign,\n",
    "CASE WHEN lower(tooltip) like '%speed%' THEN 1 ELSE 0 END AS speed_limit_sign,\n",
    "CASE WHEN lower(tooltip) like '%no u turn%' THEN 1 ELSE 0 END AS no_u_turn_sign\n",
    "from dfC a\n",
    "INNER JOIN\n",
    "location_lookup_df b\n",
    " ON a.X >= new_left AND a.X < new_right\n",
    "AND a.Y >= new_down AND a.Y < new_up\n",
    ") x\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\", locals())\n",
    "\n",
    "stop_and_yield_signs_df = ps.sqldf(\"\"\"\n",
    "SELECT\n",
    "  index1,\n",
    "  SUM(stop_sign) AS stop_sign,\n",
    "  SUM(yield_sign) AS yield_sign\n",
    "FROM\n",
    "(select index1,\n",
    "    CASE WHEN lower(tooltip) like '%stop%' THEN 1 ELSE 0 END AS stop_sign,\n",
    "    CASE WHEN lower(tooltip) like '%yield%' THEN 1 ELSE 0 END AS yield_sign\n",
    "    from dfE a\n",
    "    INNER JOIN\n",
    "    location_lookup_df b\n",
    "     ON a.X >= new_left AND a.X < new_right\n",
    "    AND a.Y >= new_down AND a.Y < new_up\n",
    "    ) x\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\"\"\", locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_granular_df = ps.sqldf(\"\"\"\n",
    "SELECT\n",
    "*\n",
    "FROM\n",
    "df a\n",
    "LEFT JOIN population_final_df b on b.index1 = a.index1\n",
    "LEFT JOIN intersections_df c on c.index1 = a.index1\n",
    "LEFT JOIN street_lights_df d on d.index1 = a.index1\n",
    "LEFT JOIN regulatory_signs_df e on e.index1 = a.index1\n",
    "LEFT JOIN stop_and_yield_signs_df f on f.index1 = a.index1\n",
    "\"\"\", locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_granular_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_granular_df['intersection']=final_granular_df['intersection'].apply(lambda l: \"Unknown\" if l == '-' else l)\n",
    "final_granular_df['weather_1']=final_granular_df['weather_1'].apply(lambda l: \"Unknown\" if l == '-' else l)\n",
    "final_granular_df['primary_coll_factor']=final_granular_df['primary_coll_factor'].apply(lambda l: \"Unknown\" if l == '-' else l)\n",
    "final_granular_df['pcf_viol_category']=final_granular_df['pcf_viol_category'].apply(lambda l: \"Unknown\" if l == '-' else l)\n",
    "final_granular_df['pcf_viol_category']=final_granular_df['pcf_viol_category'].apply(lambda l: \"Unknown\" if l == '- ' else l)\n",
    "final_granular_df['type_of_collision']=final_granular_df['type_of_collision'].apply(lambda l: \"Unknown\" if l == '-' else l)\n",
    "final_granular_df['road_surface']=final_granular_df['road_surface'].apply(lambda l: \"Unknown\" if l == '-' else l)\n",
    "final_granular_df['road_cond_1']=final_granular_df['road_cond_1'].apply(lambda l: \"Unknown\" if l == '-' else l)\n",
    "final_granular_df['lighting']=final_granular_df['lighting'].apply(lambda l: \"Unknown\" if l == '-' else l)\n",
    "final_granular_df['control_device']=final_granular_df['control_device'].apply(lambda l: \"Unknown\" if l == '-' else l)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = final_granular_df.columns\n",
    "columns\n",
    "\n",
    "for column in columns:\n",
    "    if column != \"collision_date\" and column != \"index1\" and final_granular_df[column].dtype == \"O\":\n",
    "        print(column + \" \" + str(final_granular_df[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_granular_df = ps.sqldf(\"\"\"\n",
    "SELECT\n",
    "  CASE WHEN collision_time >= 0 and collision_time < 300 THEN 1 else 0 END is_12AM_3AM,\n",
    "  CASE WHEN collision_time >= 300 and collision_time < 600 THEN 1 else 0 END is_3AM_6AM,\n",
    "  CASE WHEN collision_time >= 600 and collision_time < 900 THEN 1 else 0 END is_6AM_9AM,\n",
    "  CASE WHEN collision_time >= 900 and collision_time < 1200 THEN 1 else 0 END is_9AM_12PM,\n",
    "  CASE WHEN collision_time >= 1200 and collision_time < 1500 THEN 1 else 0 END is_12PM_3PM,\n",
    "  CASE WHEN collision_time >= 1500 and collision_time < 1800 THEN 1 else 0 END is_3PM_6PM,\n",
    "  CASE WHEN collision_time >= 1800 and collision_time < 2100 THEN 1 else 0 END is_6PM_9PM,\n",
    "  CASE WHEN collision_time >= 2100 and collision_time < 2400 THEN 1 else 0 END is_9PM_12AM,\n",
    "  CASE WHEN day_of_week = 1 THEN 1 ELSE 0 END AS is_monday,\n",
    "  CASE WHEN day_of_week = 2 THEN 1 ELSE 0 END AS is_tuesday,\n",
    "  CASE WHEN day_of_week = 3 THEN 1 ELSE 0 END AS is_wednesday,\n",
    "  CASE WHEN day_of_week = 4 THEN 1 ELSE 0 END AS is_thursday,\n",
    "  CASE WHEN day_of_week = 5 THEN 1 ELSE 0 END AS is_friday,\n",
    "  CASE WHEN day_of_week = 6 THEN 1 ELSE 0 END AS is_saturday,\n",
    "  CASE WHEN day_of_week = 7 THEN 1 ELSE 0 END AS is_sunday,\n",
    "  x.*\n",
    "FROM final_granular_df x\n",
    "\n",
    "\"\"\", locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_granular_df.to_csv(\"a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testfinal2 = pd.get_dummies(final_granular_df, drop_first=True, columns = [\n",
    "'pedestrian_accident',\n",
    "'bicycle_accident',\n",
    "'motorcycle_accident',\n",
    "'truck_accident',\n",
    "'alcohol_involved'])\n",
    "\n",
    "df_testfinal2 = pd.get_dummies(final_granular_df, columns = [\n",
    "'intersection',\n",
    "'weather_1',\n",
    "'location_type',\n",
    "'primary_coll_factor',\n",
    "'pcf_viol_category',\n",
    "'hit_and_run',\n",
    "'type_of_collision',\n",
    "'road_surface',\n",
    "'road_cond_1',\n",
    "'lighting',\n",
    "'control_device'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testfinal2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testfinal2.to_csv(\"df_testfinal2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregated Dataset\n",
    "- You can skip the code above and start here if you have this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testfinal2 = pd.read_csv(\"df_testfinal2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_aggregated_df = ps.sqldf(\"\"\"\n",
    "SELECT\n",
    "collision_date,\n",
    "SUM(is_12AM_3AM) AS is_12AM_3AM,\n",
    "SUM(is_3AM_6AM) AS is_3AM_6AM,\n",
    "SUM(is_6AM_9AM) AS is_6AM_9AM,\n",
    "SUM(is_9AM_12PM) AS is_9AM_12PM,\n",
    "SUM(is_12PM_3PM) AS is_12PM_3PM,\n",
    "SUM(is_3PM_6PM) AS is_3PM_6PM,\n",
    "SUM(is_6PM_9PM) AS is_6PM_9PM,\n",
    "SUM(is_9PM_12AM) AS is_9PM_12AM,\n",
    "SUM(is_monday) AS is_monday,\n",
    "SUM(is_tuesday) AS is_tuesday,\n",
    "SUM(is_wednesday) AS is_wednesday,\n",
    "SUM(is_thursday) AS is_thursday,\n",
    "SUM(is_friday) AS is_friday,\n",
    "SUM(is_saturday) AS is_saturday,\n",
    "SUM(is_sunday) AS is_sunday,\n",
    "AVG(Density) AS Density, \n",
    "AVG(Wealthy) AS Wealthy,\n",
    "AVG(intersections) AS intersections,\n",
    "AVG(total_watts) AS total_watts,\n",
    "AVG(total_lightbulbs) AS total_lightbulbs,\n",
    "AVG(one_way_signs) AS one_way_signs,\n",
    "AVG(speed_limit_signs) AS speed_limit_signs,\n",
    "AVG(no_u_turn_signs) AS no_u_turn_signs,\n",
    "AVG(stop_sign) AS stop_sign,\n",
    "AVG(yield_sign) AS yield_sign,\n",
    "SUM(IF(collision_severity IN (1,2), 1, 0)) AS high_severity,\n",
    "SUM(IF(collision_severity IN (1,2), 0, 1)) AS low_severity,\n",
    "SUM(number_killed) AS number_killed,\n",
    "SUM(number_injured) AS number_injured,\n",
    "SUM(pedestrian_accident) AS pedestrian_accident,\n",
    "SUM(bicycle_accident) AS bicycle_accident,\n",
    "SUM(motorcycle_accident) AS motorcycle_accident,\n",
    "SUM(truck_accident) AS truck_accident,\n",
    "SUM(alcohol_involved) AS alcohol_involved,\n",
    "SUM(count_ped_killed) AS count_ped_killed,\n",
    "SUM(count_ped_injured) AS count_ped_injured,\n",
    "SUM(count_bicyclist_killed) AS count_bicyclist_killed,\n",
    "SUM(count_bicyclist_injured) AS count_bicyclist_injured,\n",
    "SUM(intersection_N) AS intersection_N,\n",
    "SUM(intersection_Unknown) AS intersection_Unknown,\n",
    "SUM(intersection_Y) AS intersection_Y,\n",
    "SUM(weather_1_A) AS weather_1_A,\n",
    "SUM(weather_1_B) AS weather_1_B,\n",
    "SUM(weather_1_C) AS weather_1_C,\n",
    "SUM(weather_1_D) AS weather_1_D,\n",
    "SUM(weather_1_E) AS weather_1_E,\n",
    "SUM(weather_1_F) AS weather_1_F,\n",
    "SUM(weather_1_G) AS weather_1_G,\n",
    "SUM(weather_1_Unknown) AS weather_1_Unknown,\n",
    "SUM(location_type_H) AS location_type_H,\n",
    "SUM(location_type_I) AS location_type_I,\n",
    "SUM(location_type_N) AS location_type_N,\n",
    "SUM(location_type_R) AS location_type_R,\n",
    "SUM(primary_coll_factor_A) AS primary_coll_factor_A,\n",
    "SUM(primary_coll_factor_B) AS primary_coll_factor_B,\n",
    "SUM(primary_coll_factor_C) AS primary_coll_factor_C,\n",
    "SUM(primary_coll_factor_D) AS primary_coll_factor_D,\n",
    "SUM(primary_coll_factor_E) AS primary_coll_factor_E,\n",
    "SUM(primary_coll_factor_Unknown) AS primary_coll_factor_Unknown,\n",
    "SUM(pcf_viol_category_00) AS pcf_viol_category_00,\n",
    "SUM(pcf_viol_category_01) AS pcf_viol_category_01,\n",
    "SUM(pcf_viol_category_02) AS pcf_viol_category_02,\n",
    "SUM(pcf_viol_category_03) AS pcf_viol_category_03,\n",
    "SUM(pcf_viol_category_04) AS pcf_viol_category_04,\n",
    "SUM(pcf_viol_category_05) AS pcf_viol_category_05,\n",
    "SUM(pcf_viol_category_06) AS pcf_viol_category_06,\n",
    "SUM(pcf_viol_category_07) AS pcf_viol_category_07,\n",
    "SUM(pcf_viol_category_08) AS pcf_viol_category_08,\n",
    "SUM(pcf_viol_category_09) AS pcf_viol_category_09,\n",
    "SUM(pcf_viol_category_10) AS pcf_viol_category_10,\n",
    "SUM(pcf_viol_category_11) AS pcf_viol_category_11,\n",
    "SUM(pcf_viol_category_12) AS pcf_viol_category_12,\n",
    "SUM(pcf_viol_category_13) AS pcf_viol_category_13,\n",
    "SUM(pcf_viol_category_14) AS pcf_viol_category_14,\n",
    "SUM(pcf_viol_category_15) AS pcf_viol_category_15,\n",
    "SUM(pcf_viol_category_16) AS pcf_viol_category_16,\n",
    "SUM(pcf_viol_category_17) AS pcf_viol_category_17,\n",
    "SUM(pcf_viol_category_18) AS pcf_viol_category_18,\n",
    "SUM(pcf_viol_category_21) AS pcf_viol_category_21,\n",
    "SUM(pcf_viol_category_22) AS pcf_viol_category_22,\n",
    "SUM(pcf_viol_category_24) AS pcf_viol_category_24,\n",
    "SUM(pcf_viol_category_Unknown) AS pcf_viol_category_Unknown,\n",
    "SUM(hit_and_run_F) AS hit_and_run_F,\n",
    "SUM(hit_and_run_M) AS hit_and_run_M,\n",
    "SUM(hit_and_run_N) AS hit_and_run_N,\n",
    "SUM(type_of_collision_A) AS type_of_collision_A,\n",
    "SUM(type_of_collision_B) AS type_of_collision_B,\n",
    "SUM(type_of_collision_C) AS type_of_collision_C,\n",
    "SUM(type_of_collision_D) AS type_of_collision_D,\n",
    "SUM(type_of_collision_E) AS type_of_collision_E,\n",
    "SUM(type_of_collision_F) AS type_of_collision_F,\n",
    "SUM(type_of_collision_G) AS type_of_collision_G,\n",
    "SUM(type_of_collision_H) AS type_of_collision_H,\n",
    "SUM(type_of_collision_Unknown) AS type_of_collision_Unknown,\n",
    "SUM(road_surface_A) AS road_surface_A,\n",
    "SUM(road_surface_B) AS road_surface_B,\n",
    "SUM(road_surface_C) AS road_surface_C,\n",
    "SUM(road_surface_D) AS road_surface_D,\n",
    "SUM(road_surface_Unknown) AS road_surface_Unknown,\n",
    "SUM(road_cond_1_A) AS road_cond_1_A,\n",
    "SUM(road_cond_1_B) AS road_cond_1_B,\n",
    "SUM(road_cond_1_C) AS road_cond_1_C,\n",
    "SUM(road_cond_1_D) AS road_cond_1_D,\n",
    "SUM(road_cond_1_E) AS road_cond_1_E,\n",
    "SUM(road_cond_1_F) AS road_cond_1_F,\n",
    "SUM(road_cond_1_G) AS road_cond_1_G,\n",
    "SUM(road_cond_1_H) AS road_cond_1_H,\n",
    "SUM(road_cond_1_Unknown) AS road_cond_1_Unknown,\n",
    "SUM(lighting_A) AS lighting_A,\n",
    "SUM(lighting_B) AS lighting_B,\n",
    "SUM(lighting_C) AS lighting_C,\n",
    "SUM(lighting_D) AS lighting_D,\n",
    "SUM(lighting_E) AS lighting_E,\n",
    "SUM(lighting_Unknown) AS lighting_Unknown,\n",
    "SUM(control_device_A) AS control_device_A,\n",
    "SUM(control_device_B) AS control_device_B,\n",
    "SUM(control_device_C) AS control_device_C,\n",
    "SUM(control_device_D) AS control_device_D,\n",
    "SUM(control_device_Unknown) AS control_device_Unknown\n",
    "FROM df_testfinal2\n",
    "GROUP BY 1\n",
    "ORDER BY 1\n",
    "\n",
    "\"\"\", locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_aggregated_df.to_csv(\"final_aggregated_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestProject",
   "language": "python",
   "name": "testproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
