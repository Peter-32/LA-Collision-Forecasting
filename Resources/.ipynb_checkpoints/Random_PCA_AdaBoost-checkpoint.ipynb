{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS_5661 PROJECT : RedHat Business Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import all the Libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 : Read the people dataset & Print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'C:/Masters/5661/Project REDHAT/people/people.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-da9df9796c3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/Masters/5661/Project REDHAT/people/people.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cherylmariajose/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cherylmariajose/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cherylmariajose/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cherylmariajose/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cherylmariajose/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'C:/Masters/5661/Project REDHAT/people/people.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Masters/5661/Project REDHAT/people/people.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 : Read the activity_training dataset & print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_1734928</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_2434093</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_3404049</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_3651215</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_4109017</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  people_id   activity_id        date activity_category char_1 char_2 char_3  \\\n",
       "0   ppl_100  act2_1734928  2023-08-26            type 4    NaN    NaN    NaN   \n",
       "1   ppl_100  act2_2434093  2022-09-27            type 2    NaN    NaN    NaN   \n",
       "2   ppl_100  act2_3404049  2022-09-27            type 2    NaN    NaN    NaN   \n",
       "3   ppl_100  act2_3651215  2023-08-04            type 2    NaN    NaN    NaN   \n",
       "4   ppl_100  act2_4109017  2023-08-26            type 2    NaN    NaN    NaN   \n",
       "\n",
       "  char_4 char_5 char_6 char_7 char_8 char_9  char_10  outcome  \n",
       "0    NaN    NaN    NaN    NaN    NaN    NaN  type 76        0  \n",
       "1    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
       "2    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
       "3    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
       "4    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train1 = pd.read_csv(\"C:/Masters/5661/Project REDHAT/act_train/act_train.csv\")\n",
    "#df_train2 = pd.read_csv(\"C:/Masters/5661/Project REDHAT/act_train/act_train.csv\")\n",
    "df_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 : Drop some features which are difficult to convert in Activity_training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      people_id activity_category   char_1   char_2  char_3  char_4  char_5  \\\n",
      "52   ppl_100025            type 1   type 3   type 5  type 1  type 1  type 6   \n",
      "105  ppl_100033            type 1  type 36  type 11  type 5  type 1  type 6   \n",
      "106  ppl_100033            type 1  type 24   type 6  type 6  type 3  type 1   \n",
      "107  ppl_100033            type 1   type 2   type 2  type 3  type 3  type 5   \n",
      "108  ppl_100033            type 1   type 2   type 5  type 3  type 2  type 6   \n",
      "\n",
      "     char_6  char_7  char_8  char_9  outcome  \n",
      "52   type 3  type 3  type 6  type 8        0  \n",
      "105  type 1  type 1  type 4  type 1        0  \n",
      "106  type 3  type 4  type 5  type 1        0  \n",
      "107  type 2  type 2  type 4  type 2        0  \n",
      "108  type 1  type 1  type 6  type 8        0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(157615, 12)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop Charector column that are not required from feature matrix in activity table\n",
    "df_train1 = df_train1.drop('activity_id', axis=1)\n",
    "df_train1 = df_train1.drop('date', axis=1)\n",
    "df_train1 = df_train1.drop('char_10', axis=1)\n",
    "\n",
    "# drop colums with NAN for easier machine learning and remove complexity\n",
    "df_train1 = df_train1.dropna(how='any')\n",
    "\n",
    "print df_train1.head()\n",
    "df_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Perform One Hot Encoding on Activity_training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      people_id  outcome  type 1_left  type 1_right  type 10_left  \\\n",
      "52   ppl_100025        0          1.0           0.0           0.0   \n",
      "105  ppl_100033        0          1.0           0.0           0.0   \n",
      "106  ppl_100033        0          1.0           0.0           0.0   \n",
      "107  ppl_100033        0          1.0           0.0           0.0   \n",
      "108  ppl_100033        0          1.0           0.0           0.0   \n",
      "\n",
      "     type 11_left  type 12_left  type 13_left  type 14_left  type 15_left  \\\n",
      "52            0.0           0.0           0.0           0.0           0.0   \n",
      "105           0.0           0.0           0.0           0.0           0.0   \n",
      "106           0.0           0.0           0.0           0.0           0.0   \n",
      "107           0.0           0.0           0.0           0.0           0.0   \n",
      "108           0.0           0.0           0.0           0.0           0.0   \n",
      "\n",
      "      ...    type 18_right  type 19  type 2  type 3  type 4  type 5  \\\n",
      "52    ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
      "105   ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
      "106   ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
      "107   ...              0.0      0.0     1.0     0.0     0.0     0.0   \n",
      "108   ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "     type 6_right  type 7_right  type 8_right  type 9  \n",
      "52            0.0           0.0           1.0     0.0  \n",
      "105           0.0           0.0           0.0     0.0  \n",
      "106           0.0           0.0           0.0     0.0  \n",
      "107           0.0           0.0           0.0     0.0  \n",
      "108           0.0           0.0           1.0     0.0  \n",
      "\n",
      "[5 rows x 161 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(157615, 161)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform Onehot encoding on remaining feature colums\n",
    "cols_to_transform = ['activity_category','char_1','char_2','char_3','char_4','char_5','char_6','char_7','char_8','char_9']\n",
    "for colums in cols_to_transform:\n",
    "    df_with_dummies = pd.get_dummies(df_train1[colums])\n",
    "    df_train1 = df_train1.drop(colums, axis=1)\n",
    "    df_train1 = df_train1.join(df_with_dummies, lsuffix='_left', rsuffix='_right')\n",
    "\n",
    "print df_train1.head()\n",
    "df_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 : Define Label Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52         0\n",
       "105        0\n",
       "106        0\n",
       "107        0\n",
       "108        0\n",
       "124        1\n",
       "125        1\n",
       "126        1\n",
       "127        1\n",
       "128        1\n",
       "129        1\n",
       "130        1\n",
       "186        0\n",
       "187        0\n",
       "206        0\n",
       "219        1\n",
       "220        1\n",
       "231        0\n",
       "232        0\n",
       "243        0\n",
       "250        1\n",
       "251        1\n",
       "252        1\n",
       "253        1\n",
       "254        1\n",
       "261        0\n",
       "262        1\n",
       "263        0\n",
       "268        0\n",
       "279        1\n",
       "          ..\n",
       "2196920    0\n",
       "2196922    0\n",
       "2196927    0\n",
       "2196929    1\n",
       "2196930    1\n",
       "2196931    1\n",
       "2197021    0\n",
       "2197022    0\n",
       "2197023    0\n",
       "2197024    0\n",
       "2197025    0\n",
       "2197026    0\n",
       "2197027    0\n",
       "2197028    0\n",
       "2197029    0\n",
       "2197030    0\n",
       "2197031    0\n",
       "2197032    0\n",
       "2197035    1\n",
       "2197144    0\n",
       "2197157    0\n",
       "2197158    0\n",
       "2197163    0\n",
       "2197192    0\n",
       "2197195    0\n",
       "2197196    0\n",
       "2197220    1\n",
       "2197227    1\n",
       "2197233    0\n",
       "2197245    1\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_activity=df_train1['outcome']\n",
    "y_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>type 1_left</th>\n",
       "      <th>type 1_right</th>\n",
       "      <th>type 10_left</th>\n",
       "      <th>type 11_left</th>\n",
       "      <th>type 12_left</th>\n",
       "      <th>type 13_left</th>\n",
       "      <th>type 14_left</th>\n",
       "      <th>type 15_left</th>\n",
       "      <th>type 16_left</th>\n",
       "      <th>...</th>\n",
       "      <th>type 18_right</th>\n",
       "      <th>type 19</th>\n",
       "      <th>type 2</th>\n",
       "      <th>type 3</th>\n",
       "      <th>type 4</th>\n",
       "      <th>type 5</th>\n",
       "      <th>type 6_right</th>\n",
       "      <th>type 7_right</th>\n",
       "      <th>type 8_right</th>\n",
       "      <th>type 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ppl_100025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ppl_100033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ppl_100033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ppl_100033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ppl_100033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      people_id  type 1_left  type 1_right  type 10_left  type 11_left  \\\n",
       "52   ppl_100025          1.0           0.0           0.0           0.0   \n",
       "105  ppl_100033          1.0           0.0           0.0           0.0   \n",
       "106  ppl_100033          1.0           0.0           0.0           0.0   \n",
       "107  ppl_100033          1.0           0.0           0.0           0.0   \n",
       "108  ppl_100033          1.0           0.0           0.0           0.0   \n",
       "\n",
       "     type 12_left  type 13_left  type 14_left  type 15_left  type 16_left  \\\n",
       "52            0.0           0.0           0.0           0.0           0.0   \n",
       "105           0.0           0.0           0.0           0.0           0.0   \n",
       "106           0.0           0.0           0.0           0.0           0.0   \n",
       "107           0.0           0.0           0.0           0.0           0.0   \n",
       "108           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      ...    type 18_right  type 19  type 2  type 3  type 4  type 5  \\\n",
       "52    ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
       "105   ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
       "106   ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
       "107   ...              0.0      0.0     1.0     0.0     0.0     0.0   \n",
       "108   ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     type 6_right  type 7_right  type 8_right  type 9  \n",
       "52            0.0           0.0           1.0     0.0  \n",
       "105           0.0           0.0           0.0     0.0  \n",
       "106           0.0           0.0           0.0     0.0  \n",
       "107           0.0           0.0           0.0     0.0  \n",
       "108           0.0           0.0           1.0     0.0  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop label column that are not required from feature matrix in activity table to seperate y axis\n",
    "df_train1 = df_train1.drop('outcome', axis=1)\n",
    "df_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 : Drop some features which are difficult to convert in People Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    people_id  char_1  char_2   char_3   char_4  char_5  char_6   char_7  \\\n",
      "0     ppl_100  type 2  type 2   type 5   type 5  type 5  type 3  type 11   \n",
      "1  ppl_100002  type 2  type 3  type 28   type 9  type 5  type 3  type 11   \n",
      "2  ppl_100003  type 2  type 3   type 4   type 8  type 5  type 2   type 5   \n",
      "3  ppl_100004  type 2  type 3  type 40  type 25  type 9  type 4  type 16   \n",
      "4  ppl_100006  type 2  type 3  type 40  type 25  type 9  type 3   type 8   \n",
      "\n",
      "   char_8  char_9   ...   char_29 char_30 char_31 char_32 char_33 char_34  \\\n",
      "0  type 2  type 2   ...     False    True    True   False   False    True   \n",
      "1  type 2  type 4   ...     False    True    True    True    True    True   \n",
      "2  type 2  type 2   ...     False   False    True    True    True    True   \n",
      "3  type 2  type 2   ...      True    True    True    True    True    True   \n",
      "4  type 2  type 2   ...     False   False    True   False   False   False   \n",
      "\n",
      "  char_35 char_36 char_37 char_38  \n",
      "0    True    True   False      36  \n",
      "1    True    True   False      76  \n",
      "2   False    True    True      99  \n",
      "3    True    True    True      76  \n",
      "4    True    True   False      84  \n",
      "\n",
      "[5 rows x 39 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(189118, 39)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop feature column that are not required from feature matrix in people table \n",
    "df = df.drop('group_1', axis=1)\n",
    "df = df.drop('date', axis=1)\n",
    "\n",
    "print df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Perform One Hot Encoding on People Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    people_id char_10 char_11 char_12 char_13 char_14 char_15 char_16 char_17  \\\n",
      "0     ppl_100    True   False   False    True    True   False    True   False   \n",
      "1  ppl_100002   False   False    True    True   False   False   False    True   \n",
      "2  ppl_100003    True    True    True    True    True    True   False    True   \n",
      "3  ppl_100004    True    True    True    True    True   False    True    True   \n",
      "4  ppl_100006   False   False   False   False   False   False   False   False   \n",
      "\n",
      "  char_18  ...   type 8_left type 1 type 2 type 3_right type 4 type 5 type 6  \\\n",
      "0   False  ...           0.0    0.0    1.0          0.0    0.0    0.0    0.0   \n",
      "1   False  ...           0.0    0.0    0.0          0.0    1.0    0.0    0.0   \n",
      "2   False  ...           0.0    0.0    1.0          0.0    0.0    0.0    0.0   \n",
      "3    True  ...           0.0    0.0    1.0          0.0    0.0    0.0    0.0   \n",
      "4   False  ...           0.0    0.0    1.0          0.0    0.0    0.0    0.0   \n",
      "\n",
      "  type 7 type 8_right type 9  \n",
      "0    0.0          0.0    0.0  \n",
      "1    0.0          0.0    0.0  \n",
      "2    0.0          0.0    0.0  \n",
      "3    0.0          0.0    0.0  \n",
      "4    0.0          0.0    0.0  \n",
      "\n",
      "[5 rows x 161 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(189118, 161)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform Onehot encoding on remaining feature colums in people table\n",
    "col_trans_ppl = ['char_1','char_2','char_3','char_4','char_5','char_6','char_7','char_8','char_9']\n",
    "for colums in col_trans_ppl:\n",
    "    df_dummies = pd.get_dummies(df[colums])\n",
    "    df = df.drop(colums, axis=1)\n",
    "    df = df.join(df_dummies, lsuffix='_left', rsuffix='_right')\n",
    "\n",
    "print df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8 : Merge the two Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>type 1_left_x</th>\n",
       "      <th>type 1_right_x</th>\n",
       "      <th>type 10_left_x</th>\n",
       "      <th>type 11_left_x</th>\n",
       "      <th>type 12_left_x</th>\n",
       "      <th>type 13_left_x</th>\n",
       "      <th>type 14_left_x</th>\n",
       "      <th>type 15_left_x</th>\n",
       "      <th>type 16_left_x</th>\n",
       "      <th>...</th>\n",
       "      <th>type 8_left_y</th>\n",
       "      <th>type 1</th>\n",
       "      <th>type 2_y</th>\n",
       "      <th>type 3_right_y</th>\n",
       "      <th>type 4_y</th>\n",
       "      <th>type 5_y</th>\n",
       "      <th>type 6</th>\n",
       "      <th>type 7</th>\n",
       "      <th>type 8_right_y</th>\n",
       "      <th>type 9_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppl_100033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppl_100033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl_100033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    people_id  type 1_left_x  type 1_right_x  type 10_left_x  type 11_left_x  \\\n",
       "0  ppl_100025            1.0             0.0             0.0             0.0   \n",
       "1  ppl_100033            1.0             0.0             0.0             0.0   \n",
       "2  ppl_100033            1.0             0.0             0.0             0.0   \n",
       "3  ppl_100033            1.0             0.0             0.0             0.0   \n",
       "4  ppl_100033            1.0             0.0             0.0             0.0   \n",
       "\n",
       "   type 12_left_x  type 13_left_x  type 14_left_x  type 15_left_x  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   type 16_left_x    ...     type 8_left_y  type 1  type 2_y  type 3_right_y  \\\n",
       "0             0.0    ...               0.0     0.0       0.0             0.0   \n",
       "1             0.0    ...               0.0     0.0       0.0             1.0   \n",
       "2             0.0    ...               0.0     0.0       0.0             1.0   \n",
       "3             0.0    ...               0.0     0.0       0.0             1.0   \n",
       "4             0.0    ...               0.0     0.0       0.0             1.0   \n",
       "\n",
       "   type 4_y  type 5_y  type 6  type 7  type 8_right_y  type 9_y  \n",
       "0       0.0       0.0     1.0     0.0             0.0       0.0  \n",
       "1       0.0       0.0     0.0     0.0             0.0       0.0  \n",
       "2       0.0       0.0     0.0     0.0             0.0       0.0  \n",
       "3       0.0       0.0     0.0     0.0             0.0       0.0  \n",
       "4       0.0       0.0     0.0     0.0             0.0       0.0  \n",
       "\n",
       "[5 rows x 320 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_train1.merge(df, on='people_id',how='left')\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df_new['people_id'] = df_new['people_id'].astype('float64') \n",
    "#df_new = df_new.convert_objects(convert_numeric=True)\n",
    "#df_new['people_id'] = pd.to_numeric(df_new['people_id'])\n",
    "\n",
    "#Drop the People id as we have a updated Merged table with people and activity\n",
    "df_new = df_new.drop('people_id', axis=1)\n",
    "X = df_new\n",
    "\n",
    "Y = y_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9 : Split the data to do training and check for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# The function\"train_test_split\" from \"sklearn.cross_validation\" library performs random splitting.\n",
    "# \"test_size=0.3\" means that pick 30% of data samples for testing set, and the rest (70%) for training set.\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110330, 319)\n",
      "(47285, 319)\n",
      "(110330L,)\n",
      "(47285L,)\n"
     ]
    }
   ],
   "source": [
    "print x_train.shape\n",
    "print x_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10 : Reduce Dimensions as the features are too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import library for PCA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0 -29.234324 -0.518611 -0.800467 -0.528117  1.504308  0.154077  0.102118   \n",
      "1  34.862525  1.969071 -0.567406 -0.030956  0.051764 -0.071096 -0.679222   \n",
      "2  33.863945  2.208835  1.421296 -0.573907  0.378862 -0.489495 -0.643617   \n",
      "3  40.905938  2.709339  1.087537 -1.154597  0.386430 -0.504103  2.343148   \n",
      "4  36.757652 -2.100111  1.463354 -1.015044  0.628493 -0.919552  0.767708   \n",
      "\n",
      "         7         8         9     ...           40        41        42  \\\n",
      "0  0.631115  0.776177 -1.059978    ...     0.074444  0.038706 -0.274787   \n",
      "1 -0.251680 -0.016075  0.468662    ...    -0.593657  0.330028  0.342384   \n",
      "2 -0.538944  0.035243  0.943296    ...     0.384120  0.102347 -0.189715   \n",
      "3  0.199373  0.229629  0.419053    ...    -0.046309  0.294651  0.308221   \n",
      "4 -0.469864 -0.612968 -0.523451    ...     0.333443 -0.170863  0.004188   \n",
      "\n",
      "         43        44        45        46        47        48        49  \n",
      "0 -0.046073 -0.100200  0.129029 -0.075178  0.352650  0.120713  0.011693  \n",
      "1 -0.126467 -0.221733  0.050196 -0.079595 -0.027661 -0.109483  0.013532  \n",
      "2 -0.249446  0.302688  0.053764 -0.041745 -0.507108  0.745491  0.184197  \n",
      "3 -0.610036 -0.195737  0.364539 -0.354975  0.119553 -0.235674 -0.068186  \n",
      "4  0.029454  0.260234 -0.117858 -0.140538 -0.334132 -0.221581  0.260719  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# reduce dimensions. Use PCA\n",
    "pca = PCA(n_components=50)\n",
    "# train the algorithim\n",
    "pca.fit(x_train)\n",
    "# transform the vector for training set\n",
    "X_transform = pca.fit_transform(x_train)\n",
    "\n",
    "# put it into a dataframe\n",
    "X_transform = pd.DataFrame(X_transform)\n",
    "print X_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.041476</td>\n",
       "      <td>-2.142130</td>\n",
       "      <td>1.227109</td>\n",
       "      <td>-0.951787</td>\n",
       "      <td>0.887987</td>\n",
       "      <td>-0.459223</td>\n",
       "      <td>1.004788</td>\n",
       "      <td>0.153057</td>\n",
       "      <td>-0.463672</td>\n",
       "      <td>-0.090824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454618</td>\n",
       "      <td>0.413261</td>\n",
       "      <td>-0.171351</td>\n",
       "      <td>-0.476556</td>\n",
       "      <td>-0.033931</td>\n",
       "      <td>0.307234</td>\n",
       "      <td>0.248188</td>\n",
       "      <td>0.219667</td>\n",
       "      <td>-0.106704</td>\n",
       "      <td>-0.409097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.158097</td>\n",
       "      <td>1.545542</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.502839</td>\n",
       "      <td>-1.194719</td>\n",
       "      <td>-0.924412</td>\n",
       "      <td>-0.718672</td>\n",
       "      <td>0.992360</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>-0.860971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>-0.221816</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.797897</td>\n",
       "      <td>-0.434740</td>\n",
       "      <td>0.185805</td>\n",
       "      <td>-0.217531</td>\n",
       "      <td>0.196225</td>\n",
       "      <td>-0.328749</td>\n",
       "      <td>0.029738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.050672</td>\n",
       "      <td>-2.075585</td>\n",
       "      <td>-1.510147</td>\n",
       "      <td>0.711042</td>\n",
       "      <td>0.838020</td>\n",
       "      <td>-0.910129</td>\n",
       "      <td>-0.747553</td>\n",
       "      <td>-0.466721</td>\n",
       "      <td>0.113831</td>\n",
       "      <td>-0.281059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066322</td>\n",
       "      <td>0.178402</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>-0.208403</td>\n",
       "      <td>0.340111</td>\n",
       "      <td>-0.194930</td>\n",
       "      <td>0.294749</td>\n",
       "      <td>-0.014473</td>\n",
       "      <td>-0.008838</td>\n",
       "      <td>-0.299654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.173220</td>\n",
       "      <td>1.982169</td>\n",
       "      <td>0.519908</td>\n",
       "      <td>-0.619307</td>\n",
       "      <td>1.262522</td>\n",
       "      <td>0.090931</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>0.547415</td>\n",
       "      <td>0.485518</td>\n",
       "      <td>-0.308729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756567</td>\n",
       "      <td>0.394234</td>\n",
       "      <td>0.337450</td>\n",
       "      <td>-0.004689</td>\n",
       "      <td>-0.693237</td>\n",
       "      <td>-0.272591</td>\n",
       "      <td>0.162378</td>\n",
       "      <td>-0.445989</td>\n",
       "      <td>0.332378</td>\n",
       "      <td>0.020884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-48.954205</td>\n",
       "      <td>-0.040434</td>\n",
       "      <td>-0.961269</td>\n",
       "      <td>1.633794</td>\n",
       "      <td>0.896826</td>\n",
       "      <td>-0.315696</td>\n",
       "      <td>0.390336</td>\n",
       "      <td>-0.082967</td>\n",
       "      <td>-0.398101</td>\n",
       "      <td>-0.105660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206368</td>\n",
       "      <td>0.160852</td>\n",
       "      <td>0.239504</td>\n",
       "      <td>0.159363</td>\n",
       "      <td>-0.248012</td>\n",
       "      <td>-0.066552</td>\n",
       "      <td>-0.082041</td>\n",
       "      <td>0.043514</td>\n",
       "      <td>-0.016597</td>\n",
       "      <td>-0.205299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  33.041476 -2.142130  1.227109 -0.951787  0.887987 -0.459223  1.004788   \n",
       "1  41.158097  1.545542  0.765306  0.502839 -1.194719 -0.924412 -0.718672   \n",
       "2  31.050672 -2.075585 -1.510147  0.711042  0.838020 -0.910129 -0.747553   \n",
       "3  37.173220  1.982169  0.519908 -0.619307  1.262522  0.090931 -0.359381   \n",
       "4 -48.954205 -0.040434 -0.961269  1.633794  0.896826 -0.315696  0.390336   \n",
       "\n",
       "         7         8         9     ...           40        41        42  \\\n",
       "0  0.153057 -0.463672 -0.090824    ...     0.454618  0.413261 -0.171351   \n",
       "1  0.992360  0.598896 -0.860971    ...    -0.494734 -0.221816  0.006538   \n",
       "2 -0.466721  0.113831 -0.281059    ...     0.066322  0.178402  0.012317   \n",
       "3  0.547415  0.485518 -0.308729    ...     0.756567  0.394234  0.337450   \n",
       "4 -0.082967 -0.398101 -0.105660    ...    -0.206368  0.160852  0.239504   \n",
       "\n",
       "         43        44        45        46        47        48        49  \n",
       "0 -0.476556 -0.033931  0.307234  0.248188  0.219667 -0.106704 -0.409097  \n",
       "1  0.797897 -0.434740  0.185805 -0.217531  0.196225 -0.328749  0.029738  \n",
       "2 -0.208403  0.340111 -0.194930  0.294749 -0.014473 -0.008838 -0.299654  \n",
       "3 -0.004689 -0.693237 -0.272591  0.162378 -0.445989  0.332378  0.020884  \n",
       "4  0.159363 -0.248012 -0.066552 -0.082041  0.043514 -0.016597 -0.205299  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the vector for testing set\n",
    "X_transform_test = pca.fit_transform(x_test)\n",
    "# put it into a dataframe\n",
    "X_transform_test = pd.DataFrame(X_transform_test)\n",
    "\n",
    "X_transform_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11 : Perform random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest is an classifier using multiple decision trees to arive a best prediction\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "my_RandomForest = RandomForestClassifier(n_estimators = 19, bootstrap = True,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=25, n_jobs=1, oob_score=False, random_state=2,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the RandomForest alg by using the FIT method\n",
    "\n",
    "my_RandomForest.fit(X_transform,y_train,sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 0 0]\n",
      "(31523L,)\n"
     ]
    }
   ],
   "source": [
    "#Make prediction over the trained RandomForest alg using the testing sample:\n",
    "\n",
    "y_RandomForest_predict = my_RandomForest.predict(X_transform_test)\n",
    "\n",
    "print(y_RandomForest_predict)\n",
    "print(y_RandomForest_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833994226438\n"
     ]
    }
   ],
   "source": [
    "# Function \"accuracy_score\" from \"sklearn.metrics\" will perform the element-to-element comparision and returns the \n",
    "# portion of correct predictions:\n",
    "from sklearn.metrics import accuracy_score\n",
    "score_RF = accuracy_score(y_test, y_RandomForest_predict)\n",
    "print(score_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy is 0.833994226438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12 : Perform AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adaboost is a classifier which gives weightage to each features and reduces the errors in getting the best prediction\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "my_AdaBoost = AdaBoostClassifier(n_estimators=19,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=19, random_state=2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the adaboost alg by using the FIT method\n",
    "\n",
    "my_AdaBoost.fit(X_transform,y_train,sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 0 1]\n",
      "(47285L,)\n"
     ]
    }
   ],
   "source": [
    "#Make prediction over the trained Adaboost alg using the testing sample:\n",
    "\n",
    "y_adaboost_predict = my_AdaBoost.predict(X_transform_test)\n",
    "\n",
    "print(y_adaboost_predict)\n",
    "print(y_adaboost_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839462831765\n"
     ]
    }
   ],
   "source": [
    "adaboost_score = accuracy_score(y_test, y_adaboost_predict)\n",
    "\n",
    "print(adaboost_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy is 0.839462831765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  TESTING DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : Read the activity_testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100004</td>\n",
       "      <td>act1_249281</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 10</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 6</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 7</td>\n",
       "      <td>type 4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100004</td>\n",
       "      <td>act2_230855</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>type 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppl_10001</td>\n",
       "      <td>act1_240724</td>\n",
       "      <td>2022-10-14</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 12</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 4</td>\n",
       "      <td>type 6</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 13</td>\n",
       "      <td>type 10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppl_10001</td>\n",
       "      <td>act1_83552</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 20</td>\n",
       "      <td>type 10</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 4</td>\n",
       "      <td>type 6</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 5</td>\n",
       "      <td>type 5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl_10001</td>\n",
       "      <td>act2_1043301</td>\n",
       "      <td>2022-10-15</td>\n",
       "      <td>type 5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 3015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    people_id   activity_id        date activity_category   char_1   char_2  \\\n",
       "0  ppl_100004   act1_249281  2022-07-20            type 1   type 5  type 10   \n",
       "1  ppl_100004   act2_230855  2022-07-20            type 5      NaN      NaN   \n",
       "2   ppl_10001   act1_240724  2022-10-14            type 1  type 12   type 1   \n",
       "3   ppl_10001    act1_83552  2022-11-27            type 1  type 20  type 10   \n",
       "4   ppl_10001  act2_1043301  2022-10-15            type 5      NaN      NaN   \n",
       "\n",
       "   char_3  char_4  char_5  char_6  char_7   char_8   char_9    char_10  \n",
       "0  type 5  type 1  type 6  type 1  type 1   type 7   type 4        NaN  \n",
       "1     NaN     NaN     NaN     NaN     NaN      NaN      NaN   type 682  \n",
       "2  type 5  type 4  type 6  type 1  type 1  type 13  type 10        NaN  \n",
       "3  type 5  type 4  type 6  type 1  type 1   type 5   type 5        NaN  \n",
       "4     NaN     NaN     NaN     NaN     NaN      NaN      NaN  type 3015  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"C:/Masters/5661/Project REDHAT/act_test.csv\")\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 : Drop the features not required in activity_testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     people_id activity_category   char_1   char_2  char_3  char_4  char_5  \\\n",
      "0   ppl_100004            type 1   type 5  type 10  type 5  type 1  type 6   \n",
      "2    ppl_10001            type 1  type 12   type 1  type 5  type 4  type 6   \n",
      "3    ppl_10001            type 1  type 20  type 10  type 5  type 4  type 6   \n",
      "27  ppl_100010            type 1   type 2   type 1  type 9  type 3  type 1   \n",
      "28  ppl_100010            type 1   type 2   type 1  type 5  type 3  type 1   \n",
      "\n",
      "    char_6  char_7   char_8   char_9  \n",
      "0   type 1  type 1   type 7   type 4  \n",
      "2   type 1  type 1  type 13  type 10  \n",
      "3   type 1  type 1   type 5   type 5  \n",
      "27  type 3  type 2   type 2   type 1  \n",
      "28  type 3  type 1   type 2   type 1  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40092, 11)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop Charector column that are not required from feature matrix in activity table\n",
    "df_test = df_test.drop('activity_id', axis=1)\n",
    "df_test = df_test.drop('date', axis=1)\n",
    "df_test = df_test.drop('char_10', axis=1)\n",
    "\n",
    "# drop colums with NAN for easier machine learning and remove complexity\n",
    "df_test = df_test.dropna(how='any')\n",
    "\n",
    "print df_test.head()\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 : Perform One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     people_id  type 1_left  type 1_right  type 10_left  type 11_left  \\\n",
      "0   ppl_100004          1.0           0.0           0.0           0.0   \n",
      "2    ppl_10001          1.0           0.0           0.0           0.0   \n",
      "3    ppl_10001          1.0           0.0           0.0           0.0   \n",
      "27  ppl_100010          1.0           0.0           0.0           0.0   \n",
      "28  ppl_100010          1.0           0.0           0.0           0.0   \n",
      "\n",
      "    type 12_left  type 13_left  type 14_left  type 15_left  type 16_left  \\\n",
      "0            0.0           0.0           0.0           0.0           0.0   \n",
      "2            1.0           0.0           0.0           0.0           0.0   \n",
      "3            0.0           0.0           0.0           0.0           0.0   \n",
      "27           0.0           0.0           0.0           0.0           0.0   \n",
      "28           0.0           0.0           0.0           0.0           0.0   \n",
      "\n",
      "     ...    type 18_right  type 19  type 2  type 3  type 4  type 5  \\\n",
      "0    ...              0.0      0.0     0.0     0.0     1.0     0.0   \n",
      "2    ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
      "3    ...              0.0      0.0     0.0     0.0     0.0     1.0   \n",
      "27   ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
      "28   ...              0.0      0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "    type 6_right  type 7  type 8_right  type 9  \n",
      "0            0.0     0.0           0.0     0.0  \n",
      "2            0.0     0.0           0.0     0.0  \n",
      "3            0.0     0.0           0.0     0.0  \n",
      "27           0.0     0.0           0.0     0.0  \n",
      "28           0.0     0.0           0.0     0.0  \n",
      "\n",
      "[5 rows x 155 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40092, 155)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform Onehot encoding on remaining feature colums with testing dataset\n",
    "cols_to_transform = ['activity_category','char_1','char_2','char_3','char_4','char_5','char_6','char_7','char_8','char_9']\n",
    "for colums in cols_to_transform:\n",
    "    df_test_dummies = pd.get_dummies(df_test[colums])\n",
    "    df_test = df_test.drop(colums, axis=1)\n",
    "    df_test = df_test.join(df_test_dummies, lsuffix='_left', rsuffix='_right')\n",
    "\n",
    "print df_test.head()\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 : Merge People dataset with activity_testing datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>type 1_left_x</th>\n",
       "      <th>type 1_right_x</th>\n",
       "      <th>type 10_left_x</th>\n",
       "      <th>type 11_left_x</th>\n",
       "      <th>type 12_left_x</th>\n",
       "      <th>type 13_left_x</th>\n",
       "      <th>type 14_left_x</th>\n",
       "      <th>type 15_left_x</th>\n",
       "      <th>type 16_left_x</th>\n",
       "      <th>...</th>\n",
       "      <th>type 8_left_y</th>\n",
       "      <th>type 1</th>\n",
       "      <th>type 2_y</th>\n",
       "      <th>type 3_right_y</th>\n",
       "      <th>type 4_y</th>\n",
       "      <th>type 5_y</th>\n",
       "      <th>type 6</th>\n",
       "      <th>type 7_y</th>\n",
       "      <th>type 8_right_y</th>\n",
       "      <th>type 9_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_10001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppl_10001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppl_100010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl_100010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    people_id  type 1_left_x  type 1_right_x  type 10_left_x  type 11_left_x  \\\n",
       "0  ppl_100004            1.0             0.0             0.0             0.0   \n",
       "1   ppl_10001            1.0             0.0             0.0             0.0   \n",
       "2   ppl_10001            1.0             0.0             0.0             0.0   \n",
       "3  ppl_100010            1.0             0.0             0.0             0.0   \n",
       "4  ppl_100010            1.0             0.0             0.0             0.0   \n",
       "\n",
       "   type 12_left_x  type 13_left_x  type 14_left_x  type 15_left_x  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             1.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   type 16_left_x    ...     type 8_left_y  type 1  type 2_y  type 3_right_y  \\\n",
       "0             0.0    ...               0.0     0.0       1.0             0.0   \n",
       "1             0.0    ...               0.0     0.0       1.0             0.0   \n",
       "2             0.0    ...               0.0     0.0       1.0             0.0   \n",
       "3             0.0    ...               0.0     1.0       0.0             0.0   \n",
       "4             0.0    ...               0.0     1.0       0.0             0.0   \n",
       "\n",
       "   type 4_y  type 5_y  type 6  type 7_y  type 8_right_y  type 9_y  \n",
       "0       0.0       0.0     0.0       0.0             0.0       0.0  \n",
       "1       0.0       0.0     0.0       0.0             0.0       0.0  \n",
       "2       0.0       0.0     0.0       0.0             0.0       0.0  \n",
       "3       0.0       0.0     0.0       0.0             0.0       0.0  \n",
       "4       0.0       0.0     0.0       0.0             0.0       0.0  \n",
       "\n",
       "[5 rows x 315 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_test = df_test.merge(df, on='people_id',how='left')\n",
    "df_new_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type 1_left_x</th>\n",
       "      <th>type 1_right_x</th>\n",
       "      <th>type 10_left_x</th>\n",
       "      <th>type 11_left_x</th>\n",
       "      <th>type 12_left_x</th>\n",
       "      <th>type 13_left_x</th>\n",
       "      <th>type 14_left_x</th>\n",
       "      <th>type 15_left_x</th>\n",
       "      <th>type 16_left_x</th>\n",
       "      <th>type 17_left_x</th>\n",
       "      <th>...</th>\n",
       "      <th>type 8_left_y</th>\n",
       "      <th>type 1</th>\n",
       "      <th>type 2_y</th>\n",
       "      <th>type 3_right_y</th>\n",
       "      <th>type 4_y</th>\n",
       "      <th>type 5_y</th>\n",
       "      <th>type 6</th>\n",
       "      <th>type 7_y</th>\n",
       "      <th>type 8_right_y</th>\n",
       "      <th>type 9_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type 1_left_x  type 1_right_x  type 10_left_x  type 11_left_x  \\\n",
       "0            1.0             0.0             0.0             0.0   \n",
       "1            1.0             0.0             0.0             0.0   \n",
       "2            1.0             0.0             0.0             0.0   \n",
       "3            1.0             0.0             0.0             0.0   \n",
       "4            1.0             0.0             0.0             0.0   \n",
       "\n",
       "   type 12_left_x  type 13_left_x  type 14_left_x  type 15_left_x  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             1.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   type 16_left_x  type 17_left_x    ...     type 8_left_y  type 1  type 2_y  \\\n",
       "0             0.0             0.0    ...               0.0     0.0       1.0   \n",
       "1             0.0             0.0    ...               0.0     0.0       1.0   \n",
       "2             0.0             0.0    ...               0.0     0.0       1.0   \n",
       "3             0.0             0.0    ...               0.0     1.0       0.0   \n",
       "4             0.0             0.0    ...               0.0     1.0       0.0   \n",
       "\n",
       "   type 3_right_y  type 4_y  type 5_y  type 6  type 7_y  type 8_right_y  \\\n",
       "0             0.0       0.0       0.0     0.0       0.0             0.0   \n",
       "1             0.0       0.0       0.0     0.0       0.0             0.0   \n",
       "2             0.0       0.0       0.0     0.0       0.0             0.0   \n",
       "3             0.0       0.0       0.0     0.0       0.0             0.0   \n",
       "4             0.0       0.0       0.0     0.0       0.0             0.0   \n",
       "\n",
       "   type 9_y  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop the People id as we have a updated Merged table with people and activity\n",
    "df_new_test = df_new_test.drop('people_id', axis=1)\n",
    "X_test = df_new_test\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 : Reduce dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0  27.568422  3.130501  1.416779  1.275329  0.280165 -0.265865  0.162398   \n",
      "1  41.573366  2.890950  1.359723 -0.269297  0.554963 -0.662387 -1.043203   \n",
      "2  41.574411  2.877926  1.272128 -0.459267  0.502563 -0.404015 -0.987178   \n",
      "3 -46.543884  0.258002 -0.122537 -0.703620 -0.926126  0.470036 -0.106347   \n",
      "4 -46.543065  0.346750  0.566293 -0.663952 -0.728687  0.009842 -0.256566   \n",
      "\n",
      "         7         8         9     ...           40        41        42  \\\n",
      "0 -0.902504  0.015296  0.678656    ...     0.055981 -0.036713  0.471439   \n",
      "1 -0.326068 -0.380162 -0.065214    ...     0.313879 -0.231620 -0.431102   \n",
      "2 -0.476238 -0.129361 -0.023998    ...     0.255975 -0.571686 -0.007371   \n",
      "3  0.607468  0.291233 -1.403201    ...     0.243033  0.476894  0.317730   \n",
      "4  0.462832  0.040748 -1.276175    ...     0.431738  0.751787  0.328953   \n",
      "\n",
      "         43        44        45        46        47        48        49  \n",
      "0 -0.258120 -0.226639  0.647843  0.350770  0.032199  0.163802  0.047941  \n",
      "1  0.408988  0.014916  0.202576 -0.105539 -0.397168 -0.244762  0.040557  \n",
      "2  0.504995 -0.074563  0.086862 -0.175011  0.158600 -0.575313 -0.060692  \n",
      "3 -0.014982  0.884453  0.197182  0.068343 -0.031822  0.234741  0.527506  \n",
      "4 -0.206823  0.730233  0.012718 -0.045847 -0.112259  0.354473  0.464338  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# transform the vector for training set\n",
    "X_test_transform = pca.fit_transform(X_test)\n",
    "\n",
    "# put it into a dataframe\n",
    "X_test_transform = pd.DataFrame(X_test_transform)\n",
    "print X_test_transform.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 : Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 1]\n",
      "(40092L,)\n"
     ]
    }
   ],
   "source": [
    "#Make prediction over the trained RandomForest alg using the testing sample:\n",
    "\n",
    "y_RandomForest_predict_test = my_RandomForest.predict(X_test_transform)\n",
    "\n",
    "print(y_RandomForest_predict_test)\n",
    "print(y_RandomForest_predict_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7 : Save the results into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('C:/Masters/5661/Project REDHAT/myresultRedHat.csv', \n",
    "           y_RandomForest_predict_test, \n",
    "           delimiter=',', \n",
    "           fmt='%3i', \n",
    "           header='Results of Random tree prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
